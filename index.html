<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="GradiSeg: Gradient-Guided Gaussian Segmentation with Enhanced 3D Boundary Precision">
  <meta property="og:title" content="GradiSeg: Gradient-Guided Gaussian Segmentation with Enhanced 3D Boundary Precision"/>
  <meta property="og:description" content="Introducing GradiSeg, a gradient-guided framework based on 3D Gaussians that enhances boundary segmentation."/>
  <meta property="og:url" content="https://github.com/AlphaGoLzh/GardiSeg"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/gradiseg-banner.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="GradiSeg: Gradient-Guided Gaussian Segmentation with Enhanced 3D Boundary Precision">
  <meta name="twitter:description" content="Introducing GradiSeg, a gradient-guided framework based on 3D Gaussians that enhances boundary segmentation.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/gradiseg-twitter.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="3D Gaussians, Segmentation, Scene Understanding, Gradient">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>GradiSeg: Gradient-Guided Gaussian Segmentation with Enhanced 3D Boundary Precision</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">GradiSeg: Gradient-Guided Gaussian Segmentation with Enhanced 3D Boundary Precision</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block"> <a href="https://alphagolzh.github.io/" target="_blank">Zehao Li</a><sup>1,2</sup>, </span>
              <span class="author-block"> Wenwei Han</a><sup>1,2</sup>, </span>
              <span class="author-block"> <a href="https://vanoracai.github.io/" target="_blank">Yujun Cai</a><sup>3</sup>, </span>
              <span class="author-block"> Hao Jiang</a><sup>1,2*</sup>, </span><br>
              <span class="author-block"> <a href="https://byronbbl.github.io/" target="_blank">Baolong Bi</a><sup>1,2</sup>, </span>
              <span class="author-block"> Shuqin Gao</a><sup>1</sup>, </span>
              <span class="author-block"> Honglong Zhao</a><sup>1</sup>, </span>
              <span class="author-block"> Zhaoqi Wang</a><sup>1,2</sup>, </span>
              </div>

              <div class="is-size-6 publication-authors">
              <span class="author-block"><sup>1</sup>Institute of Computing Technology, Chinese Academy of Sciences, ICT</span><br>
              <span class="author-block"><sup>2</sup>University of Chinese Academy of Sciences, UCAS</span><br>
              <span class="author-block"><sup>3</sup>The University of Queensland</span>
              </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                    <span class="link-block">
                        <a href="https://arxiv.org/abs/2412.00392" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arxiv</span>
                      </a>
                    </span>
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2412.00392" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code(coming soon)</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            While 3D Gaussian Splatting enables high-quality real-time rendering, existing Gaussian-based frameworks for 3D semantic segmentation still face significant challenges in <strong>boundary recognition accuracy</strong>. 
          </p>
          <p>
            To address this, we propose a novel 3DGS-based framework named <strong>GradiSeg</strong>, incorporating Identity Encoding to construct a deeper semantic understanding of scenes. Our approach introduces two key modules:  Identity Gradient Guided Densification (IGD) and Local Adaptive K-Nearest Neighbors (LA-KNN).
          </p>
          <p>
            The IGD module supervises gradients of Identity Encoding to refine Gaussian distributions along object boundaries, aligning them closely with boundary contours. Meanwhile, the LA-KNN module employs position gradients to adaptively establish locality-aware propagation of Identity Encodings, preventing irregular Gaussian spreads near boundaries.
          </p>
          <p>
            We validate the effectiveness of our method through comprehensive experiments. Results show that GradiSeg effectively addresses boundary-related issues, significantly improving <strong>segmentation accuracy</strong> without compromising scene <strong>reconstruction quality</strong>. Furthermore, our method's robust segmentation capability and decoupled Identity Encoding representation make it highly suitable for various downstream scene editing tasks, including 3D object removal, swapping and so on.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section"  style="padding: 0rem 2rem;">
  <div class="container is-max-desktop">
    <!-- 标题部分 -->
    <div class="content" style="max-width: 1000px; margin: 0 auto;">
      <center><img src="static/images/framework.png" alt="teaser" width="100%"></center>
      <br>   
    <!-- 文本部分 -->
      <p style="font-size: 1.1rem; line-height: 1.8; text-align: left; margin-top: 0.5rem;">
        🔥 Overview of the proposed method. a) We adopt Identity Encoding as a learnable vector to construct a semantic understanding of the scene. This vector is optimized through multi-view supervision to produce initial segmentation results. b) To tackle boundary ambiguity, we introduce two boundary enhancement modules: IGD and LA-KNN. IGD refines Gaussians near object boundaries by monitoring Identity Encoding gradients. Complementarily, LA-KNN enables direction-aware feature propagation by leveraging position gradients for neighbor selection, preventing cross-instance feature contamination at boundaries.
      </p>    
    </div>
  </div>
</section>

<section class="section" style="background-color: #f9f9f7;”>
  <div class="container is-max-desktop">
    <div class="columns is-vcentered" style="display: flex; justify-content: center; max-width: 900px; margin: 0 auto; align-items: center;">
      
      <div style="flex: 0 0 50%; padding-right: 20px; padding-left: 30px;">
        <img src="static/images/igd.png" alt="IGD Module" style="width: 100%; height: auto;">
      </div>

      <!-- 右侧文本 -->
      <div style="flex: 0 0 50%; padding-left: 20px; padding-left: 30px;">  <!-- 文本区域占60% -->
        <div class="content">
          <h2 class="title is-3">IGD Module</h2>
          <p>
            The process of the IGD module. The first row refers to Identity Encoding gradient monitoring. For Gaussians near the boundaries, in order to optimize, they continuously adjust their Identity Encoding, leading to an increasingly high gradient that may become anomalous. The second row involves Identity Encoding densification. For Gaussians with anomalous gradients, we perform splitting and adjust them to both sides of the boundary, addressing optimization conflicts during the training process.
          </p>
        </div>
      </div>
      
    </div>
  </div>
</section>

  <section class="section" style="background-color: #eef4fa;”>
  <div class="container is-max-desktop">
    <div class="columns is-vcentered" style="display: flex; justify-content: center; max-width: 900px; margin: 0 auto; align-items: center;">

       <!-- 左侧文本 -->
      <div style="flex: 0 0 50%; padding-left: 20px; padding-left: 30px;">  <!-- 文本区域占60% -->
        <div class="content">
          <h2 class="title is-3">LA-KNN Module</h2>
          <p>
            The process of the LA-KNN module. We first compute the neighboring direction by taking the opposite direction of the Gaussian position gradient. Then, we eliminate all Gaussians whose angle with the direction vector is greater than 180 degrees. For the remaining Gaussians, we sort them by their projection distance to the direction vector and select the $K$ nearest neighbors. Finally, we align the Identity Encoding features in the local space.
          </p>
        </div>
      </div>
      
      <div style="flex: 0 0 50%; padding-right: 20px; padding-left: 30px;">
        <img src="static/images/laknn.png" alt="LA-KNN Module" style="width: 100%; height: auto;">
      </div>

     
      
    </div>
  </div>
</section>


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
        </div>
      </div>
    </div>
  </div>

     <section class="section" style="padding: 3rem 2rem;">
  <div class="container is-max-desktop">
    
    <!-- 标题部分 -->
    <div class="content" style="max-width: 1000px; margin: 0 auto;">
      <h2 class="title is-3" style="color: #4a235a; text-align: center;">
        Comparative Study on Segmentation and Reconstruction 
      </h2>
      <p style="font-size: 1.1rem; line-height: 1.8; text-align: left;">
        We conduct open-vocabulary segmentation comparison experiments on the LERF-Mask dataset and reconstruction quality comparison experiments on the Mip-NeRF 360 dataset. The results show that our method improves semantic segmentation accuracy, especially at boundaries, without compromising image reconstruction quality.
      </p>
    </div>

    <!-- 图表部分 -->
    <figure class="image" style="margin: 2rem auto; text-align: center;">
    <img src="static/images/visual.png" background-color: #f5f5f5; alt="Open-vocabulary Segmentation Comparison"  max-width: 100%; height: auto; style="border-radius: 8px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);display: block; margin: 0 auto;">
    <figcaption style="font-size: 0.9rem; color: #4a235a; margin-top: 0.5rem;">Figure 1: The visualization comparison results on the LERF-Mask dataset.</figcaption>
    </figure>
    <figure class="image" style="margin: 2rem auto; text-align: center;">
      <img src="static/images/rec.png" background-color: #f5f5f5; alt="Comparative Study of Reconstruction Quality"  max-width: 100%; height: auto; style="border-radius: 8px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1); display: block; margin: 0 auto;">
      <figcaption style="font-size: 0.9rem; color: #4a235a; margin-top: 0.5rem;">Figure 2: The visualization comparison results of reconstruction quality.</figcaption>
    </figure>

    <!-- 结尾部分 -->
    <div class="content" style="max-width: 1000px; margin: 2rem auto;">
      <p style="font-size: 1.1rem; line-height: 1.8; text-align: left;">
        In this work, we propose GradiSeg, a novel 3D semantic segmentation framework that enhances boundary precision. By integrating Identity Gradient Guided Densification and Local Adaptive K-Nearest Neighbors, our method refines Gaussians near boundaries and ensures Identity Encoding consistency in local 3D spaces, reducing feature propagation errors. Experiments on LERF-Mask and MipNeRF 360 confirm GradiSeg’s superior performance in segmentation quality.

  </div>
</section>


    <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{li2024gradiseggradientguidedgaussiansegmentation,
      title={GradiSeg: Gradient-Guided Gaussian Segmentation with Enhanced 3D Boundary Precision}, 
      author={Zehao Li and Wenwei Han and Yujun Cai and Hao Jiang and Baolong Bi and Shuqin Gao and Honglong Zhao and Zhaoqi Wang},
      year={2024},
      eprint={2412.00392},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.00392}, 
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
